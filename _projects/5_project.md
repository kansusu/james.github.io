---
layout: page
title: iSAT
description:
img: assets/img/isat_classroom_graphic_only_2022_0.jpg
importance: 3
category: fun
---

<!-- Main content of the project -->
<div class="content">
     <div class="row">
         <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/action.png" title="example image" class="img-fluid rounded z-depth-1" %}
    </div>
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/deixis.png" title="example image" class="img-fluid rounded z-depth-1" %}
    </div>
    </div>
       <div class="caption" style="text-align: left; font-size: 1.1rem;">
    <p>The NSF AI Institute for Student-AI Teaming (iSAT) is centered around the question: how to promote deep conceptual learning via rich socio-collaborative learning experiences for all students?</p>

    <p>The goal of iSAT is to develop an AI Partner that will guide and scaffold learning conversations among students, as well as help teachers orchestrate effective collaborative learning experiences. Believing that natural, multimodal interaction will deepen engagement with the AI Partner, we have been developing methods for representing and interpreting the meanings expressed in gesture and other forms of nonverbal communication. For example, our lab has extended Abstract Meaning Representation to gesture and action, allowing us to analyze the alignment of these modalities with language. We are also working on approaches for gesture and posture detection and classification in video. Finally, we have created an annotation scheme and dataset for tracking common ground in dialogue.</p>

</div>
   
</div>
